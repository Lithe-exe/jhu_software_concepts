--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
--only-binary=:all:

Flask>=2.3,<4
huggingface_hub>=0.23.0

llama-cpp-python==0.3.2
